{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to _netrics_: a Python 2.7 module for the econometric analysis of network data\n",
    "<br>\n",
    "_Bryan Graham - University of California - Berkeley_\n",
    "<br>\n",
    "_September 2016_ \n",
    "<br>\n",
    "<br>\n",
    "**Code citation:**\n",
    "<br>\n",
    "<br>\n",
    "Graham, Bryan S. (2016). \"Introduction to _netrics_: a Python 2.7 module for the econometric analysis of network data,\" (Version 1.0) [Computer program]. Available at http://bryangraham.github.io/econometrics/ (Accessed 04 Sept 2016) \n",
    "<br>\n",
    "<br>\n",
    "**Paper citation:**\n",
    "<br>\n",
    "<br>\n",
    "Graham, Bryan S. (2014). “An econometric model of link formation with degree heterogeneity,” NBER Working Paper No. 20341. Available at http://www.nber.org/papers/w20341 \n",
    "<br>\n",
    "<br>\n",
    "This notebook provides a quick introduction to the main features of the **netrics** package. This package is registered on PyPi, with a GitHub repository at https://github.com/bryangraham/netrics. This package provides an implementation of the _tetrad logit_ and _joint logit fixed effects_ estimators introduced in Graham (2014).\n",
    "<br>\n",
    "<br>\n",
    "The **netrics** package has the following dependencies: numpy, scipy, itertools, pandas, numba and numexpr. These are standard libraries and are included in most scientific Python distributions. For example they are included in the highly recommended Anaconda distribution of Python. If you are using the Anaconda distribution of Python, then you can follow the (straightforward but tedious) instructions here to learn how install the netrics package from PyPi and make it available in Anaconda using the \"conda\" package manager. For users who anticipate only infrequent use, permanent installation of the **netrics** package may not be worth the trouble. One possibility is to just clone (ie., copy) the GitHub repository https://github.com/bryangraham/netrics, which contains the latest version of **netrics**. Then append the path pointing to the location of the package on your local machine to your sys directory. This is what is done in the next snippet of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy in order to correctly read test data\n",
    "import numpy as np\n",
    "\n",
    "# Import urllib in order to download test data from Github repo\n",
    "import urllib\n",
    "\n",
    "# Append location of netrics module base directory to system path\n",
    "# NOTE: only required if permanent install not made (see comments above)\n",
    "import sys\n",
    "sys.path.append('/Users/bgraham/Dropbox/Sites/software/netrics/')\n",
    "\n",
    "# Load netrics module\n",
    "import netrics as netrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purposes I make use of a cleaned version of the Nyakatoke risk-sharing network data collected by Joachim de Weerdt. The raw files are available for download at https://www.uantwerpen.be/en/staff/joachim-deweerdt/ (where links to research based on the data may also be found). I have placed a cleaned numpy pickle file with an estimation sample on the GitHub repository for the **netrics** package. This next snippet of code downloads this file and prepares the data for input into the *tetrad\\_logit()* and *dyad\\_jfe\\_logit()* functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download Nyakatoke test dataset from GitHub\n",
    "download =  '/Users/bgraham/Dropbox/'                               # Edit to download location on your local machine   \n",
    "url = 'https://github.com/bryangraham/netrics/blob/master/Notebooks/Nyakatoke_Example.npz?raw=true'\n",
    "urllib.urlretrieve(url, download + \"Nyakatoke_Example.npz\")\n",
    "\n",
    "# Open dataset\n",
    "NyakatokeTestDataset = np.load(download + \"Nyakatoke_Example.npz\")\n",
    "\n",
    "# Extract adjacency matrix\n",
    "D = NyakatokeTestDataset['D']\n",
    "\n",
    "# Initialize list of dyad-specific covariates as elements\n",
    "# W = [W0, W1, W2,...WK-1]\n",
    "W = []\n",
    "\n",
    "# Initialize list with covariate labels\n",
    "cov_names = []\n",
    "\n",
    "# Construct list of regressor matrices and corresponding variable names\n",
    "for matrix in NyakatokeTestDataset.files:\n",
    "    if matrix != 'D':\n",
    "        W.append(NyakatokeTestDataset[matrix])\n",
    "        cov_names.append(matrix)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I fit the a dyadic link formation model to the Nyakatoke dataset using the two estimators introduced by Graham (2014, _NBER_). The link formation model studied in that paper is\n",
    "\n",
    "\n",
    "<div> $$\\Pr\\left(\\left.D_{ij}=1\\right|\\mathbf{X},\\mathbf{A}\\right) = \\frac{\\exp\\left(\\sum_{k=1}^{K}W_{k,ij}\\beta_{k}+A_{i}+A_{j}\\right)}   {1+\\exp\\left(\\sum_{k=1}^{K}W_{k,ij}\\beta_{k}+A_{i}+A_{j}\\right)}$$ </div>\n",
    "\n",
    "Here $\\mathbf{X}$ denotes all the household-specific observed covariates in the network, $W_{k,ij} = W_{k,ji}$ are dyad-specific covariates constructed from $\\mathbf{X}$, and the $A_i$ for $i=1,...,N$ are _degree heterogeneity_ parameters which are household specific. These are treated as co-called \"fixed effects\".\n",
    "<br>\n",
    "<br>\n",
    "Graham (2014) introduces a \"tetrad logit\" procedure whose criterion function is invariant to the fixed effects and also a \"joint logit fixed effects\" procedure which estimates the individual effects along with the common parameters.\n",
    "<br>\n",
    "<br>\n",
    "In the **netrics** package these two procedures are operationalized by the *tetrad\\_logit()* and *dyad\\_jfe\\_logit()* functions. These two functions require the user to input data in a very particular way. The outcome is $\\mathbf{D}$, the $N \\times N$ adjacency matrix. The regressors are included in a length $K$ list where each element is an $N \\times N $ numpy 2d array $W_{k}$ with $(i,j)$ element equal to the dyadic covariate $W_{k,ij}$. \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tetrad Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A help call gives some basic information about *tetrad\\_logit()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function tetrad_logit in module netrics.tetrad_logit:\n",
      "\n",
      "tetrad_logit(D, W, dtcon=None, silent=False, W_names=None)\n",
      "    AUTHOR: Bryan S. Graham, bgraham@econ.berkeley.edu, June 2016\n",
      "    \n",
      "    This function computes the Tetrad Logit estimator introduced in Graham (2014, NBER No. 20341) -- \"An Econometric\n",
      "    Model of Link Formation with Degree Heterogeneity\". The implementation is as described in the paper. Notation\n",
      "    attempts to follow that used in the paper.\n",
      "    \n",
      "    INPUTS\n",
      "    ------\n",
      "    D                 : N x N undirected adjacency matrix\n",
      "    W                 : List with elements consisting of N x N 2d numpy arrays of dyad-specific \n",
      "                        covariates such that W[k][i,j] gives the k-th covariate for dyad ij\n",
      "    dtcon             : Dyad and tetrad concordance (dtcon) List with elements [tetrad_to_dyads_indices, \n",
      "                        dyad_to_tetrads_dict]. If dtcon=None, then construct it using generate_tetrad_indices() \n",
      "                        function. See header to generate_tetrad_indices() for more information.\n",
      "    silent            : If True then suppress all optimization and estimation output, show output otherwise.  \n",
      "    W_names           : List of K strings giving names of the columns of W_tilde. If silent=False then use\n",
      "                        these in presentation of estimation output.\n",
      "                   \n",
      "    OUTPUTS\n",
      "    -------\n",
      "    beta_TL          :  K x 1 vector of tetrad logit point estimates of beta\n",
      "    vcov_beta_TL     :  K x K asymptotic-variance matrix for beta_TL \n",
      "                        NOTE: vcov_beta_TL is already \"divided by n\" (just take square root of diagonal for std. errs.)\n",
      "    tetrad_frac_TL   :  Fraction of tetrads that contribute to Tetrad Logit criterion function                    \n",
      "    success          :  corresponds to success component of OptimizeResult associated with Scipy's minimize function;\n",
      "                        success = True if the tetrad logit optimizer exited successfully\n",
      "            \n",
      "    \n",
      "    CALLS:           : ...logit()...\n",
      "                       ...organize_data_tetrad_logit()...\n",
      "    ------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(netrics.tetrad_logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next call tetrad_logit(). Depending on the speed and memory of your computer, this next bit of code may take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher-Scoring Derivative check (2-norm): 4.71127475\n",
      "Value of -logL = 138316.376938,  2-norm of score = 10100196.293330\n",
      "Value of -logL = 135187.248221,  2-norm of score = 1596218.251378\n",
      "Value of -logL = 135076.189036,  2-norm of score = 455357.680707\n",
      "Value of -logL = 134067.546456,  2-norm of score = 360772.909168\n",
      "Value of -logL = 132607.914482,  2-norm of score = 195723.087456\n",
      "Value of -logL = 132227.469603,  2-norm of score = 90172.252165\n",
      "Value of -logL = 119215.459180,  2-norm of score = 774170.803557\n",
      "Value of -logL = 119190.326354,  2-norm of score = 29152.067642\n",
      "Value of -logL = 115270.688302,  2-norm of score = 100160.420467\n",
      "Value of -logL = 115270.231607,  2-norm of score = 21801.989553\n",
      "Value of -logL = 110870.099449,  2-norm of score = 129096.779425\n",
      "Value of -logL = 110869.345531,  2-norm of score = 16812.212740\n",
      "Value of -logL = 108924.012970,  2-norm of score = 28476.501285\n",
      "Value of -logL = 105502.848936,  2-norm of score = 110760.679701\n",
      "Value of -logL = 105502.272215,  2-norm of score = 11564.394548\n",
      "Value of -logL = 104010.910754,  2-norm of score = 19122.141380\n",
      "Value of -logL = 101374.122914,  2-norm of score = 72971.431707\n",
      "Value of -logL = 101373.860508,  2-norm of score = 8180.643698\n",
      "Value of -logL = 98881.158747,  2-norm of score = 60032.128419\n",
      "Value of -logL = 98880.975358,  2-norm of score = 6422.992839\n",
      "Value of -logL = 97133.052526,  2-norm of score = 39620.604441\n",
      "Value of -logL = 97132.970095,  2-norm of score = 5055.675431\n",
      "Value of -logL = 96314.600881,  2-norm of score = 12852.603860\n",
      "Value of -logL = 96314.591203,  2-norm of score = 4368.510389\n",
      "Value of -logL = 95916.410702,  2-norm of score = 4434.480988\n",
      "Value of -logL = 95239.500891,  2-norm of score = 17660.352550\n",
      "Value of -logL = 95239.483618,  2-norm of score = 2648.136936\n",
      "Value of -logL = 95063.083093,  2-norm of score = 2610.810526\n",
      "Value of -logL = 94768.324201,  2-norm of score = 7527.154149\n",
      "Value of -logL = 94768.320919,  2-norm of score = 1559.382435\n",
      "Value of -logL = 94645.156780,  2-norm of score = 2119.366431\n",
      "Value of -logL = 94515.878315,  2-norm of score = 9991.950890\n",
      "Value of -logL = 94515.872559,  2-norm of score = 136.277028\n",
      "Value of -logL = 94515.818274,  2-norm of score = 118.491145\n",
      "Value of -logL = 94515.399614,  2-norm of score = 65.994736\n",
      "Value of -logL = 94515.145885,  2-norm of score = 17.980048\n",
      "Value of -logL = 94515.145885,  2-norm of score = 6.476217\n",
      "Value of -logL = 94515.145020,  2-norm of score = 5.561045\n",
      "Value of -logL = 94515.143582,  2-norm of score = 3.628944\n",
      "Value of -logL = 94515.142466,  2-norm of score = 0.757182\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.046187\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.010255\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.001471\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.000033\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.000011\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 94515.142405\n",
      "         Iterations: 45\n",
      "         Function evaluations: 159\n",
      "         Gradient evaluations: 192\n",
      "         Hessian evaluations: 46\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "- TETRAD LOGIT ESTIMATION RESULTS                                                         -\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Number of agents,           N :             115\n",
      "Number of dyads,            n :           6,555\n",
      "Number of tetrads             :       6,913,340\n",
      "Number identifying tetrads    :         102,151\n",
      "Fraction identifying tetrads  :        0.014776\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.) \n",
      "-------------------------------------------------------------------------------------------\n",
      "Distance                  -0.002083 (  0.000319)\n",
      "NonAdjacentWealthClass    -0.262694 (  0.175229)\n",
      "OtherBlood                 1.252720 (  0.293468)\n",
      "SameReligion               0.236759 (  0.141679)\n",
      "SameEdLvl                 -0.012042 (  0.151148)\n",
      "AgeDiff                   -0.014838 (  0.006137)\n",
      "Sibling                    2.714449 (  0.417002)\n",
      "SameClan                   0.277682 (  0.217226)\n",
      "AdjacentWealthClass       -0.226542 (  0.160744)\n",
      "Cousin                     2.038704 (  0.378834)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "[beta_TL, vcov_beta_TL, tetrad_frac_TL, success] = \\\n",
    "    netrics.tetrad_logit(D, W, dtcon=None, silent=False, W_names=cov_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program spits out some useful information. In a network with $N = 115$ agents there are a total of $6,913,340$ different tetrads! Of these only $102,151$, or about 1.5 percent, actually contribute to the *tetrad\\_logit()* criterion function. The effectiveness of the procedure in the context of sparse networks is one of its theoretical and practical attractions.\n",
    "<br>\n",
    "<br>\n",
    "The results suggest that ties are more frequent between households which are physically close, related by blood and where the household heads are close in age. There is little evidence for sorting by religion, clan or education. There is some evidence for heterophily in terms of wealth (perhaps consistent with some models of \"mutual support\"), but it is rather weak.\n",
    "<br>\n",
    "<br>\n",
    "The *tetrad\\_logit()* estimation procedure is computationally intense. On a modern desktop machine it would be difficult to use the procedure on a network larger than a few hundred agents (fortunately there are many possible ways to apply the method at scale via various approximations and parallelizations; but these extensions are not (yet) part of the **netrics** package). \n",
    "<br>\n",
    "<br>\n",
    "Part of the computational intensity is up front. Specifically, the function computes a detailed dictionary which maps dyads-to-tetrads and vice-versa. This bookkeeping overhead makes later calculations much quicker. A user who anticipates fitting several different models to the same adjacency matrix can save considerable time by computing this concordance first (once and for all) and then passing it to *tetrad\\_logit()* via the _dtcon_ parameter. This can be done by calling the *generate\\_tetrad\\_indices()* function.\n",
    "<br>\n",
    "<br>\n",
    "To illustrate I create the concordance and then re-fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher-Scoring Derivative check (2-norm): 4.71127475\n",
      "Value of -logL = 138316.376938,  2-norm of score = 10100196.293330\n",
      "Value of -logL = 135187.248221,  2-norm of score = 1596218.251378\n",
      "Value of -logL = 135076.189036,  2-norm of score = 455357.680707\n",
      "Value of -logL = 134067.546456,  2-norm of score = 360772.909168\n",
      "Value of -logL = 132607.914482,  2-norm of score = 195723.087456\n",
      "Value of -logL = 132227.469603,  2-norm of score = 90172.252165\n",
      "Value of -logL = 119215.459180,  2-norm of score = 774170.803557\n",
      "Value of -logL = 119190.326354,  2-norm of score = 29152.067642\n",
      "Value of -logL = 115270.688302,  2-norm of score = 100160.420467\n",
      "Value of -logL = 115270.231607,  2-norm of score = 21801.989553\n",
      "Value of -logL = 110870.099449,  2-norm of score = 129096.779425\n",
      "Value of -logL = 110869.345531,  2-norm of score = 16812.212740\n",
      "Value of -logL = 108924.012970,  2-norm of score = 28476.501285\n",
      "Value of -logL = 105502.848936,  2-norm of score = 110760.679701\n",
      "Value of -logL = 105502.272215,  2-norm of score = 11564.394548\n",
      "Value of -logL = 104010.910754,  2-norm of score = 19122.141380\n",
      "Value of -logL = 101374.122914,  2-norm of score = 72971.431707\n",
      "Value of -logL = 101373.860508,  2-norm of score = 8180.643698\n",
      "Value of -logL = 98881.158747,  2-norm of score = 60032.128419\n",
      "Value of -logL = 98880.975358,  2-norm of score = 6422.992839\n",
      "Value of -logL = 97133.052526,  2-norm of score = 39620.604441\n",
      "Value of -logL = 97132.970095,  2-norm of score = 5055.675431\n",
      "Value of -logL = 96314.600881,  2-norm of score = 12852.603860\n",
      "Value of -logL = 96314.591203,  2-norm of score = 4368.510389\n",
      "Value of -logL = 95916.410702,  2-norm of score = 4434.480988\n",
      "Value of -logL = 95239.500891,  2-norm of score = 17660.352550\n",
      "Value of -logL = 95239.483618,  2-norm of score = 2648.136936\n",
      "Value of -logL = 95063.083093,  2-norm of score = 2610.810526\n",
      "Value of -logL = 94768.324201,  2-norm of score = 7527.154149\n",
      "Value of -logL = 94768.320919,  2-norm of score = 1559.382435\n",
      "Value of -logL = 94645.156780,  2-norm of score = 2119.366431\n",
      "Value of -logL = 94515.878315,  2-norm of score = 9991.950890\n",
      "Value of -logL = 94515.872559,  2-norm of score = 136.277028\n",
      "Value of -logL = 94515.818274,  2-norm of score = 118.491145\n",
      "Value of -logL = 94515.399614,  2-norm of score = 65.994736\n",
      "Value of -logL = 94515.145885,  2-norm of score = 17.980048\n",
      "Value of -logL = 94515.145885,  2-norm of score = 6.476217\n",
      "Value of -logL = 94515.145020,  2-norm of score = 5.561045\n",
      "Value of -logL = 94515.143582,  2-norm of score = 3.628944\n",
      "Value of -logL = 94515.142466,  2-norm of score = 0.757182\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.046187\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.010255\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.001471\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.000033\n",
      "Value of -logL = 94515.142405,  2-norm of score = 0.000011\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 94515.142405\n",
      "         Iterations: 45\n",
      "         Function evaluations: 159\n",
      "         Gradient evaluations: 192\n",
      "         Hessian evaluations: 46\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "- TETRAD LOGIT ESTIMATION RESULTS                                                         -\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Number of agents,           N :             115\n",
      "Number of dyads,            n :           6,555\n",
      "Number of tetrads             :       6,913,340\n",
      "Number identifying tetrads    :         102,151\n",
      "Fraction identifying tetrads  :        0.014776\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.) \n",
      "-------------------------------------------------------------------------------------------\n",
      "Distance                  -0.002083 (  0.000319)\n",
      "NonAdjacentWealthClass    -0.262694 (  0.175229)\n",
      "OtherBlood                 1.252720 (  0.293468)\n",
      "SameReligion               0.236759 (  0.141679)\n",
      "SameEdLvl                 -0.012042 (  0.151148)\n",
      "AgeDiff                   -0.014838 (  0.006137)\n",
      "Sibling                    2.714449 (  0.417002)\n",
      "SameClan                   0.277682 (  0.217226)\n",
      "AdjacentWealthClass       -0.226542 (  0.160744)\n",
      "Cousin                     2.038704 (  0.378834)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N = np.shape(D)[0]\n",
    "concordance = netrics.generate_tetrad_indices(N, full_set=True)\n",
    "[beta_TL, vcov_beta_TL, tetrad_frac_TL, success] = \\\n",
    "    netrics.tetrad_logit(D, W, dtcon=concordance, silent=False, W_names=cov_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint Fixed Effects Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graham (2014) also introduces a joint fixed effects estimator for link formation. This procedure estimates the coefficients on $W_{k,ij}$ for $k=1,...,K$ _as well as_ individual specific degree heterogeneity parameters $A_{i}$ for $i=1,...,N$. The *dyad\\_jfe\\_logit()* function implements this estimator. By default if reports the iterated bias-corrected estimates described in the paper (but the uncorrected estimates are also returned by the function). I use the tetrad logit point estimates as starting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[beta_JFE, beta_JFE_BC, vcov_beta_JFE, A_JFE, success] = \\\n",
    "    netrics.dyad_jfe_logit(D, W, T=None, silent=False, W_names=cov_names, beta_sv=beta_TL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes some time for *dyad\\_jfe\\_logit()* to converge (even with the carefully chosen starting values). This reflects the sparsity of the Nyakatoke network and the consequent difficulty of estimating the household degree heterogeneity effects.\n",
    "<br>\n",
    "<br>\n",
    "Relative to the *tetrad\\_logit()* results, the joint estimator suggests sorting by religion and clan. In Monte Carlo experiments I have found that the joint estimator -- particularly the bias correction step -- can work very poorly in networks like the Nyakatoke one (i.e., in networks that are sparse such that many agents have only a few links). In such settings the $A_{i}$ for $i=1,...,N$ may be _very_ imprecisely estimated and this can effect the quality of the common parameter estimates as well.\n",
    "<br>\n",
    "<br>\n",
    "For reference we can look at the joint coefficient estimates prior to bias correction using the *print\\_coef()* utility included in the **netrics** package. These point estimates are closer to the *tetrad\\_logit()* ones than their bias-corrected counterparts. This suggests, that in this particular example, bias-correction may be doing more harm that good.\n",
    "<br>\n",
    "<br>\n",
    "Monte Carlo evidence suggests that in denser networks, the size distortion causes by bias in the limit distribution of the joint fixed effects estimator is very real and, furthermore, that bias correction can be effective in such contexts. So not too much should be made of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netrics.print_coef(beta_JFE, vcov_beta_JFE, var_names=cov_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to add additional functionality to the package over time. In the meantime please feel free to touch base with bug reports and/or suggestions for improvements. Unfortunately I cannot provide any meaningful user support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This imports an attractive notebook style from Github\n",
    "from IPython.core.display import HTML\n",
    "import urllib2\n",
    "HTML(urllib2.urlopen('http://bit.ly/1Bf5Hft').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
